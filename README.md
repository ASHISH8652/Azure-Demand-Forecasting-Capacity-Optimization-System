# ğŸš€ Azure Demand Forecasting & Capacity Optimization System
## ğŸ“Š End-to-End Azure Capacity Optimization  & Demand Forecasting Project

An end-to-end data engineering and machine learning project designed to analyze, clean, validate, and prepare Azure cloud demand data for intelligent forecasting and capacity planning.
--
This project simulates a real-world cloud infrastructure analytics pipeline, following professional ML workflow practices across four milestones.
--

## ğŸŒ Overview

> Cloud service providers must forecast infrastructure demand accurately to:
> Prevent over-provisioning (wasted cost)
> Prevent under-provisioning (service outages)
> Maintain high availability
> Optimize operational efficiency
> This project builds a structured system to:
---
## ğŸŒŸ Key Features (Implemented)
âœ” Clean real-world noisy cloud data

âœ” Validate business constraints

âœ” Analyze demand patterns

âœ” Prepare data for forecasting models

âœ” Eventually deploy a forecasting pipeline

---
---
## ğŸ—ï¸ Project Architecture (Milestone-Based Development)
```
Azure-Demand-Forecasting-System/
â”‚
â”œâ”€â”€ milestone1_data_cleaning/
â”‚   â”œâ”€â”€ notebook.ipynb
â”‚   â”œâ”€â”€ cleaned_dataset.csv
â”‚
â”œâ”€â”€ milestone2_feature_engineering/
â”‚
â”œâ”€â”€ milestone3_model_training/
â”‚
â”œâ”€â”€ milestone4_deployment/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_dataset.csv
â”‚
â”œâ”€â”€ images/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```
---
## ğŸ§¹ Milestone 1 â€“ Data Cleaning & Exploratory Data Analysis

* Milestone 1 focuses on transforming a noisy bi-weekly Azure dataset into a validated, production-ready dataset.
---
## ğŸ” Dataset Features
* Column	Description 
* time_stamp	Bi-weekly usage date
* region	Azure deployment region
* service_type	Compute / Storage
* usage_units	Actual demand
* provisioned_capacity	Allocated capacity
* cost_usd	Usage cost
* availability_pct	Service uptime percentage
* âš™ï¸ Data Quality Issues Handled
---
### The raw dataset intentionally contained:

* Missing values (~5%)
* Duplicate records (~3%)
* Inconsistent region formatting
* Cost rounding inconsistencies
* Business rule violations
  
### ğŸ›  Cleaning Steps Implemented

âœ” Duplicate removal
âœ” Missing value imputation
âœ” Datetime conversion
âœ” Region standardization
âœ” Time-series interpolation
âœ” Cost rounding correction
âœ” Business validation rules
âœ” Final dataset verification

### ğŸ“ˆ Exploratory Data Analysis

## Milestone 1 includes:

ğŸ“Š Overall demand trend over time
ğŸ“Š Region-wise average demand
ğŸ“Š Service-type specific demand trend
ğŸ“Š Statistical summary validation

## ğŸ§  Technologies Used

* **Python 3.9+**
* **Pandas**
* **NumPy**
* **Matplotlib**
* **Jupyter Notebook**

## ğŸ“Š Business Validation Logic

### To ensure real-world correctness:
* Usage must not exceed provisioned capacity
* Availability must remain between 90% â€“ 100%
* Cost values standardized to 2 decimal precision
* Time-series data properly formatted

## ğŸš€ Upcoming Milestones
ğŸ”¹ Milestone 2 â€“ Feature Engineering

* Lag features
* Rolling averages
* Seasonality extraction
* Trend decomposition

ğŸ”¹ Milestone 3 â€“ Model Development

* ARIMA / SARIMA
* LSTM
* Regression baselines
* Model evaluation metrics

ğŸ”¹ Milestone 4 â€“ Deployment

* Streamlit dashboard
* Forecast visualization
* Real-time prediction interface

## ğŸ“Œ Academic & Industry Value

âœ” End-to-end ML pipeline thinking
âœ” Real-world cloud infrastructure use case
âœ” Business validation rules applied
âœ” Clean structured repository
âœ” Scalable system architecture

## ğŸ‘¨â€ğŸ’» Author

Ashish Kumar Prusty
B.Tech â€“ Artificial Intelligence & Machine Learning
GitHub: https://github.com/ASHISH8652

## ğŸ“œ License

This project is licensed under the MIT License.

â€œData is not useful until it is clean, validated, and trusted.â€
